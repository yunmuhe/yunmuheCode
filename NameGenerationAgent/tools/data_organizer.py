"""
æ•°æ®æ•´ç†å’Œè½¬æ¢å·¥å…·
å°†æ‰€æœ‰txtå’Œxlsxæ–‡ä»¶è½¬æ¢ä¸ºcsvæ ¼å¼ï¼Œå¹¶æŒ‰ç±»åˆ«åˆ†ç±»å­˜å‚¨
"""
import os
import shutil
import pandas as pd
from pathlib import Path

class DataOrganizer:
    """æ•°æ®æ•´ç†å™¨"""
    
    def __init__(self, corpus_path: str = None):
        """
        åˆå§‹åŒ–æ•´ç†å™¨
        
        Args:
            corpus_path: è¯­æ–™åº“æ ¹ç›®å½•
        """
        if corpus_path is None:
            project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
            corpus_path = os.path.join(os.path.dirname(project_root), 'Chinese-Names-Corpus-master')
        
        self.corpus_path = corpus_path
        
        # è¾“å‡ºæ ¹ç›®å½•
        self.output_root = os.path.join(
            os.path.dirname(os.path.dirname(os.path.abspath(__file__))),
            'data', 'organized'
        )
        
        # åˆ›å»ºåˆ†ç±»ç›®å½•
        self.categories = {
            'chinese_names': os.path.join(self.output_root, 'ä¸­æ–‡äººå'),
            'ancient_names': os.path.join(self.output_root, 'å¤ä»£äººå'),
            'surnames': os.path.join(self.output_root, 'å§“æ°åº“'),
            'japanese_names': os.path.join(self.output_root, 'æ—¥æ–‡äººå'),
            'english_names': os.path.join(self.output_root, 'è‹±æ–‡äººå'),
            'chengyu': os.path.join(self.output_root, 'æˆè¯­è¯å…¸'),
            'relationships': os.path.join(self.output_root, 'ç§°å‘¼å…³ç³»'),
            'poetic_names': os.path.join(self.output_root, 'è¯—è¯åå­—'),
            'themed_names': os.path.join(self.output_root, 'ä¸»é¢˜åå­—'),
            'other': os.path.join(self.output_root, 'å…¶ä»–æ•°æ®'),
        }
        
        # åˆ›å»ºæ‰€æœ‰ç›®å½•
        for category_path in self.categories.values():
            os.makedirs(category_path, exist_ok=True)
    
    def organize_all(self):
        """æ•´ç†æ‰€æœ‰æ•°æ®"""
        print("=" * 70)
        print("æ•°æ®æ•´ç†å’Œè½¬æ¢å·¥å…·")
        print("=" * 70)
        print("\nå°†æ‰§è¡Œä»¥ä¸‹æ“ä½œ:")
        print("  1. è½¬æ¢æ‰€æœ‰txtæ–‡ä»¶ä¸ºcsvæ ¼å¼")
        print("  2. è½¬æ¢æ‰€æœ‰xlsxæ–‡ä»¶ä¸ºcsvæ ¼å¼")
        print("  3. æŒ‰ç±»åˆ«åˆ†ç±»å­˜å‚¨")
        print("  4. ç”Ÿæˆæ•°æ®ç›®å½•æ¸…å•")
        print("\nåˆ†ç±»ç›®å½•:")
        for name, path in self.categories.items():
            print(f"  - {os.path.basename(path)}")
        
        print("\n" + "-" * 70)
        
        # 1. è½¬æ¢txtæ–‡ä»¶
        print("\n[1/4] è½¬æ¢txtæ–‡ä»¶...")
        self.convert_txt_files()
        
        # 2. è½¬æ¢xlsxæ–‡ä»¶
        print("\n[2/4] è½¬æ¢xlsxæ–‡ä»¶...")
        self.convert_xlsx_files()
        
        # 3. åˆ†ç±»æ•´ç†
        print("\n[3/4] åˆ†ç±»æ•´ç†æ–‡ä»¶...")
        self.classify_files()
        
        # 4. ç”Ÿæˆç›®å½•æ¸…å•
        print("\n[4/4] ç”Ÿæˆæ•°æ®ç›®å½•...")
        self.generate_catalog()
        
        print("\n" + "=" * 70)
        print("âœ… æ•°æ®æ•´ç†å®Œæˆï¼")
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {self.output_root}")
        print("=" * 70)
    
    def convert_txt_files(self):
        """è½¬æ¢æ‰€æœ‰txtæ–‡ä»¶ä¸ºcsvæ ¼å¼"""
        txt_files = []
        
        # æŸ¥æ‰¾æ‰€æœ‰txtæ–‡ä»¶
        for root, dirs, files in os.walk(self.corpus_path):
            for file in files:
                if file.endswith('.txt') and not file.startswith('.'):
                    txt_files.append(os.path.join(root, file))
        
        print(f"   æ‰¾åˆ° {len(txt_files)} ä¸ªtxtæ–‡ä»¶")
        
        converted_count = 0
        for txt_file in txt_files:
            try:
                self._convert_txt_to_csv(txt_file)
                converted_count += 1
            except Exception as e:
                print(f"   âŒ è½¬æ¢å¤±è´¥: {os.path.basename(txt_file)} - {str(e)}")
        
        print(f"   âœ… æˆåŠŸè½¬æ¢ {converted_count}/{len(txt_files)} ä¸ªæ–‡ä»¶")
    
    def _convert_txt_to_csv(self, txt_file: str):
        """
        è½¬æ¢å•ä¸ªtxtæ–‡ä»¶ä¸ºcsv
        
        Args:
            txt_file: txtæ–‡ä»¶è·¯å¾„
        """
        base_name = os.path.splitext(os.path.basename(txt_file))[0]
        
        # è¯»å–txtæ–‡ä»¶
        with open(txt_file, 'r', encoding='utf-8') as f:
            lines = [line.strip() for line in f if line.strip()]
        
        # åˆ¤æ–­æ˜¯å¦åŒ…å«é€—å·åˆ†éš”çš„æ•°æ®
        if lines and ',' in lines[0]:
            # å·²ç»æ˜¯CSVæ ¼å¼ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰æ ‡é¢˜è¡Œ
            if lines[0].lower().startswith('dict') or 'å§“å' in lines[0] or 'name' in lines[0].lower():
                # æœ‰æ ‡é¢˜è¡Œ
                header = lines[0].split(',')
                data = [line.split(',') for line in lines[1:]]
            else:
                # æ²¡æœ‰æ ‡é¢˜è¡Œï¼Œæ·»åŠ é»˜è®¤æ ‡é¢˜
                header = ['column_' + str(i+1) for i in range(len(lines[0].split(',')))]
                data = [line.split(',') for line in lines]
            
            df = pd.DataFrame(data, columns=header)
        else:
            # å•åˆ—æ•°æ®
            # æ ¹æ®æ–‡ä»¶ååˆ¤æ–­åˆ—å
            if 'äººå' in base_name or 'Names' in base_name or 'name' in base_name.lower():
                column_name = 'å§“å'
            elif 'æˆè¯­' in base_name or 'ChengYu' in base_name:
                column_name = 'æˆè¯­'
            else:
                column_name = 'å†…å®¹'
            
            df = pd.DataFrame(lines, columns=[column_name])
        
        # ç¡®å®šè¾“å‡ºè·¯å¾„ï¼ˆä¸´æ—¶å­˜å‚¨ï¼‰
        temp_dir = os.path.join(self.output_root, '_temp')
        os.makedirs(temp_dir, exist_ok=True)
        
        output_file = os.path.join(temp_dir, f"{base_name}.csv")
        df.to_csv(output_file, index=False, encoding='utf-8-sig')
        
        print(f"   âœ… {base_name}: {len(df)} è¡Œ")
    
    def convert_xlsx_files(self):
        """è½¬æ¢æ‰€æœ‰xlsxæ–‡ä»¶ä¸ºcsvæ ¼å¼"""
        xlsx_files = []
        
        # æŸ¥æ‰¾æ‰€æœ‰xlsxæ–‡ä»¶
        for root, dirs, files in os.walk(self.corpus_path):
            for file in files:
                if file.endswith('.xlsx') and not file.startswith('~'):
                    xlsx_files.append(os.path.join(root, file))
        
        print(f"   æ‰¾åˆ° {len(xlsx_files)} ä¸ªxlsxæ–‡ä»¶")
        
        converted_count = 0
        for xlsx_file in xlsx_files:
            try:
                self._convert_xlsx_to_csv(xlsx_file)
                converted_count += 1
            except Exception as e:
                print(f"   âŒ è½¬æ¢å¤±è´¥: {os.path.basename(xlsx_file)} - {str(e)}")
        
        print(f"   âœ… æˆåŠŸè½¬æ¢ {converted_count}/{len(xlsx_files)} ä¸ªæ–‡ä»¶")
    
    def _convert_xlsx_to_csv(self, xlsx_file: str):
        """è½¬æ¢xlsxæ–‡ä»¶ä¸ºcsv"""
        base_name = os.path.splitext(os.path.basename(xlsx_file))[0]
        
        # è¯»å–æ‰€æœ‰sheet
        excel_data = pd.read_excel(xlsx_file, sheet_name=None, engine='openpyxl')
        
        temp_dir = os.path.join(self.output_root, '_temp')
        os.makedirs(temp_dir, exist_ok=True)
        
        # å¦‚æœæœ‰å¤šä¸ªsheet
        if len(excel_data) > 1:
            for sheet_name, df in excel_data.items():
                output_file = os.path.join(temp_dir, f"{base_name}_{sheet_name}.csv")
                df.to_csv(output_file, index=False, encoding='utf-8-sig')
        else:
            sheet_name = list(excel_data.keys())[0]
            df = excel_data[sheet_name]
            output_file = os.path.join(temp_dir, f"{base_name}.csv")
            df.to_csv(output_file, index=False, encoding='utf-8-sig')
    
    def classify_files(self):
        """åˆ†ç±»æ•´ç†æ–‡ä»¶"""
        temp_dir = os.path.join(self.output_root, '_temp')
        
        if not os.path.exists(temp_dir):
            print("   âš ï¸  æ²¡æœ‰æ‰¾åˆ°ä¸´æ—¶æ–‡ä»¶")
            return
        
        csv_files = [f for f in os.listdir(temp_dir) if f.endswith('.csv')]
        print(f"   æ•´ç† {len(csv_files)} ä¸ªcsvæ–‡ä»¶")
        
        classified = {key: [] for key in self.categories.keys()}
        
        for csv_file in csv_files:
            category = self._determine_category(csv_file)
            source_path = os.path.join(temp_dir, csv_file)
            dest_path = os.path.join(self.categories[category], csv_file)
            
            # å¤åˆ¶æ–‡ä»¶åˆ°åˆ†ç±»ç›®å½•
            shutil.copy2(source_path, dest_path)
            classified[category].append(csv_file)
        
        # æ˜¾ç¤ºåˆ†ç±»ç»“æœ
        for category, files in classified.items():
            if files:
                category_name = os.path.basename(self.categories[category])
                print(f"   ğŸ“ {category_name}: {len(files)} ä¸ªæ–‡ä»¶")
        
        # æ¸…ç†ä¸´æ—¶ç›®å½•
        shutil.rmtree(temp_dir)
        print("   âœ… åˆ†ç±»å®Œæˆ")
    
    def _determine_category(self, filename: str) -> str:
        """
        æ ¹æ®æ–‡ä»¶åç¡®å®šåˆ†ç±»
        
        Args:
            filename: æ–‡ä»¶å
            
        Returns:
            åˆ†ç±»é”®
        """
        filename_lower = filename.lower()
        
        # ä¸­æ–‡äººå
        if 'chinese_names_corpus_gender' in filename_lower or 'ä¸­æ–‡äººå' in filename:
            if 'gender' in filename_lower or 'æ€§åˆ«' in filename:
                return 'chinese_names'
        
        if 'chinese_names_corpus' in filename_lower and 'gender' not in filename_lower:
            return 'chinese_names'
        
        # å¤ä»£äººå
        if 'ancient' in filename_lower or 'å¤ä»£' in filename:
            return 'ancient_names'
        
        # å§“æ°
        if 'family_name' in filename_lower or 'surname' in filename_lower or 'å§“æ°' in filename or 'å§“' in filename:
            return 'surnames'
        
        # æ—¥æ–‡äººå
        if 'japanese' in filename_lower or 'æ—¥æ–‡' in filename or 'æ—¥æœ¬' in filename:
            return 'japanese_names'
        
        # è‹±æ–‡äººå
        if 'english' in filename_lower or 'è‹±æ–‡' in filename or 'è‹±è¯­' in filename:
            return 'english_names'
        
        # æˆè¯­
        if 'chengyu' in filename_lower or 'æˆè¯­' in filename:
            return 'chengyu'
        
        # ç§°å‘¼å…³ç³»
        if 'relationship' in filename_lower or 'ç§°å‘¼' in filename or 'å…³ç³»' in filename:
            return 'relationships'
        
        # è¯—è¯åå­—
        if 'è¯—è¯' in filename or 'æˆè¯­å–å' in filename:
            return 'poetic_names'
        
        # ä¸»é¢˜åå­—
        if 'èŒå' in filename or 'æ˜¥å¤ç§‹å†¬' in filename or 'qqç½‘å' in filename_lower or 'ä¸»é¢˜' in filename:
            return 'themed_names'
        
        # å…¶ä»–
        return 'other'
    
    def generate_catalog(self):
        """ç”Ÿæˆæ•°æ®ç›®å½•æ¸…å•"""
        catalog = []
        catalog.append("=" * 70)
        catalog.append("æ•°æ®ç›®å½•æ¸…å•")
        catalog.append("=" * 70)
        catalog.append("")
        
        total_files = 0
        total_rows = 0
        
        for category_key, category_path in self.categories.items():
            category_name = os.path.basename(category_path)
            csv_files = [f for f in os.listdir(category_path) if f.endswith('.csv')]
            
            if not csv_files:
                continue
            
            catalog.append(f"\nã€{category_name}ã€‘")
            catalog.append("-" * 70)
            
            category_rows = 0
            for csv_file in sorted(csv_files):
                file_path = os.path.join(category_path, csv_file)
                try:
                    df = pd.read_csv(file_path, encoding='utf-8-sig')
                    rows = len(df)
                    cols = len(df.columns)
                    category_rows += rows
                    catalog.append(f"  âœ… {csv_file}")
                    catalog.append(f"     è¡Œæ•°: {rows:,} | åˆ—æ•°: {cols} | åˆ—å: {', '.join(df.columns[:5])}")
                except Exception as e:
                    catalog.append(f"  âŒ {csv_file} - è¯»å–å¤±è´¥")
            
            catalog.append(f"\n  å°è®¡: {len(csv_files)} ä¸ªæ–‡ä»¶, {category_rows:,} è¡Œæ•°æ®")
            total_files += len(csv_files)
            total_rows += category_rows
        
        catalog.append("")
        catalog.append("=" * 70)
        catalog.append(f"æ€»è®¡: {total_files} ä¸ªæ–‡ä»¶, {total_rows:,} è¡Œæ•°æ®")
        catalog.append("=" * 70)
        
        # ä¿å­˜ç›®å½•æ¸…å•
        catalog_file = os.path.join(self.output_root, 'DATA_CATALOG.txt')
        with open(catalog_file, 'w', encoding='utf-8') as f:
            f.write('\n'.join(catalog))
        
        # æ‰“å°åˆ°æ§åˆ¶å°
        print('\n'.join(catalog[-10:]))  # åªæ‰“å°æœ€å10è¡Œ
        print(f"\n   ğŸ“„ å®Œæ•´ç›®å½•å·²ä¿å­˜: DATA_CATALOG.txt")
    
    def get_statistics(self) -> dict:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        stats = {}
        
        for category_key, category_path in self.categories.items():
            category_name = os.path.basename(category_path)
            csv_files = [f for f in os.listdir(category_path) if f.endswith('.csv')]
            
            if csv_files:
                total_rows = 0
                for csv_file in csv_files:
                    file_path = os.path.join(category_path, csv_file)
                    try:
                        df = pd.read_csv(file_path, encoding='utf-8-sig')
                        total_rows += len(df)
                    except:
                        pass
                
                stats[category_name] = {
                    'files': len(csv_files),
                    'rows': total_rows
                }
        
        return stats


def main():
    """ä¸»å‡½æ•°"""
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                 æ•°æ®æ•´ç†å’Œè½¬æ¢å·¥å…·                                 â•‘
â•‘          Data Organization and Conversion Tool                    â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

åŠŸèƒ½è¯´æ˜:
  â€¢ è½¬æ¢æ‰€æœ‰txtæ–‡ä»¶ä¸ºcsvæ ¼å¼
  â€¢ è½¬æ¢æ‰€æœ‰xlsxæ–‡ä»¶ä¸ºcsvæ ¼å¼
  â€¢ æŒ‰ç±»åˆ«åˆ†ç±»å­˜å‚¨æ•°æ®
  â€¢ ç”Ÿæˆæ•°æ®ç›®å½•æ¸…å•

åˆ†ç±»ç›®å½•:
  ğŸ“ ä¸­æ–‡äººå - ç°ä»£ä¸­æ–‡äººåæ•°æ®
  ğŸ“ å¤ä»£äººå - å¤ä»£äººåæ•°æ®
  ğŸ“ å§“æ°åº“ - ä¸­æ–‡å§“æ°æ•°æ®
  ğŸ“ æ—¥æ–‡äººå - æ—¥æ–‡å§“åæ•°æ®
  ğŸ“ è‹±æ–‡äººå - è‹±æ–‡å§“åæ•°æ®
  ğŸ“ æˆè¯­è¯å…¸ - æˆè¯­æ•°æ®
  ğŸ“ ç§°å‘¼å…³ç³» - ç§°å‘¼å…³ç³»æ•°æ®
  ğŸ“ è¯—è¯åå­— - è¯—è¯æˆè¯­é£æ ¼åå­—
  ğŸ“ ä¸»é¢˜åå­— - å­£èŠ‚ã€ç½‘åç­‰ä¸»é¢˜åå­—
  ğŸ“ å…¶ä»–æ•°æ® - æœªåˆ†ç±»æ•°æ®

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    # æ£€æŸ¥ä¾èµ–
    try:
        import pandas
        import openpyxl
    except ImportError:
        print("âŒ ç¼ºå°‘å¿…è¦çš„åº“ï¼")
        print("\nè¯·å®‰è£…ä¾èµ–:")
        print("  pip install pandas openpyxl")
        return
    
    organizer = DataOrganizer()
    
    response = input("æ˜¯å¦å¼€å§‹æ•´ç†ï¼Ÿ(y/n): ").strip().lower()
    
    if response == 'y':
        print("\nå¼€å§‹æ•´ç†...\n")
        organizer.organize_all()
        
        # æ˜¾ç¤ºç»Ÿè®¡
        stats = organizer.get_statistics()
        print("\n" + "=" * 70)
        print("ğŸ“Š æ•°æ®ç»Ÿè®¡:")
        for category, data in stats.items():
            print(f"  {category}: {data['files']} ä¸ªæ–‡ä»¶, {data['rows']:,} è¡Œæ•°æ®")
        
        print("\nâœ¨ æ‰€æœ‰æ•°æ®å·²æ•´ç†å®Œæˆï¼")
        print(f"ğŸ“ æ•°æ®ç›®å½•: {organizer.output_root}")
        print("\nä½¿ç”¨æ–¹æ³•:")
        print("  1. æŸ¥çœ‹å®Œæ•´ç›®å½•: cat data/organized/DATA_CATALOG.txt")
        print("  2. æµè§ˆåˆ†ç±»æ•°æ®: ls data/organized/*/")
        print("  3. åŠ è½½æ•°æ®: pandas.read_csv('data/organized/ä¸­æ–‡äººå/xxx.csv')")
        print("\n" + "=" * 70)
    else:
        print("\nå·²å–æ¶ˆæ•´ç†ã€‚")


if __name__ == '__main__':
    main()

